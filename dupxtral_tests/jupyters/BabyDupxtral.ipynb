{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.197791Z",
     "start_time": "2024-06-22T15:41:39.574128Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from transformers.models.dupxtral.configuration_dupxtral import DupxtralConfig\n",
    "from transformers.models.mixtral.configuration_mixtral import MixtralConfig\n",
    "\n",
    "from transformers.models.dupxtral.modeling_dupxtral import DupxtralModel\n",
    "from transformers.models.mixtral.modeling_mixtral import MixtralModel\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbff09d0ae84c71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.203727Z",
     "start_time": "2024-06-22T15:41:41.199754Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "N_expert = 8\n",
    "N_hidden_layers = 4\n",
    "\n",
    "\n",
    "# All layers have the same duplication pattern\n",
    "duplicate_experts = [[3, 2, 2, 1, 3, 1, 1, 1] for _ in range(N_hidden_layers)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912f76b06572f946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.215485Z",
     "start_time": "2024-06-22T15:41:41.205133Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# We remap the experts randomly: each initial expert usage is remapped to a random duplicate\n",
    "pair_remaping = [dict() for _ in range(N_hidden_layers)]\n",
    "\n",
    "for l in range(N_hidden_layers):\n",
    "    for i in range(N_expert):\n",
    "        for j in range(N_expert):\n",
    "            n_dup_i = duplicate_experts[l][i]\n",
    "            n_dup_j = duplicate_experts[l][j]\n",
    "            \n",
    "            s_i = sum(duplicate_experts[l][:i])\n",
    "            s_j = sum(duplicate_experts[l][:j])\n",
    "\n",
    "            # random remapping\n",
    "            \n",
    "            new_i = s_i + torch.randint(0, n_dup_i, (1,)).item()\n",
    "            new_j = s_j + torch.randint(0, n_dup_j, (1,)).item()\n",
    "\n",
    "            pair_remaping[l][(i, j)] = (new_i, new_j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499199259247454",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38a6b4ad5a618431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.220089Z",
     "start_time": "2024-06-22T15:41:41.216608Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We make initialize two dummy models. One normal mixtral and one dupxtral with the same configuration + duplication\n",
    "\n",
    "config_dupxtral = DupxtralConfig(hidden_size=16, num_hidden_layers=N_hidden_layers, num_local_experts=N_expert,\n",
    "                                 intermediate_size=32,\n",
    "                                 num_attention_heads=8, experts_duplicate=duplicate_experts,\n",
    "                                 vocab_size=128, experts_remapping=pair_remaping,\n",
    "                                 )\n",
    "\n",
    "config_mixtral = MixtralConfig(hidden_size=16, num_hidden_layers=N_hidden_layers, num_local_experts=N_expert,\n",
    "                               intermediate_size=32,\n",
    "                               num_attention_heads=8,\n",
    "                               vocab_size=128,\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8650ed9851151791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.277255Z",
     "start_time": "2024-06-22T15:41:41.221007Z"
    }
   },
   "outputs": [],
   "source": [
    "# We build the models architecture and initialize the weights randomly\n",
    "\n",
    "initial_model = MixtralModel(config=config_mixtral)\n",
    "\n",
    "dupxtral_model = DupxtralModel(config=config_dupxtral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6cd023b3200e6b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.281149Z",
     "start_time": "2024-06-22T15:41:41.278775Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "785d0aa4f74e5ad8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.284493Z",
     "start_time": "2024-06-22T15:41:41.282356Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3e40b4cdbf1c9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.301842Z",
     "start_time": "2024-06-22T15:41:41.286103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.block_sparse_moe.experts.0.w1.weight layers.0.block_sparse_moe.experts.0.w1.weight\n",
      "layers.0.block_sparse_moe.experts.0.w2.weight layers.0.block_sparse_moe.experts.0.w2.weight\n",
      "layers.0.block_sparse_moe.experts.0.w3.weight layers.0.block_sparse_moe.experts.0.w3.weight\n",
      "layers.0.block_sparse_moe.experts.1.w1.weight layers.0.block_sparse_moe.experts.0.w1.weight\n",
      "layers.0.block_sparse_moe.experts.1.w2.weight layers.0.block_sparse_moe.experts.0.w2.weight\n",
      "layers.0.block_sparse_moe.experts.1.w3.weight layers.0.block_sparse_moe.experts.0.w3.weight\n",
      "layers.0.block_sparse_moe.experts.2.w1.weight layers.0.block_sparse_moe.experts.0.w1.weight\n",
      "layers.0.block_sparse_moe.experts.2.w2.weight layers.0.block_sparse_moe.experts.0.w2.weight\n",
      "layers.0.block_sparse_moe.experts.2.w3.weight layers.0.block_sparse_moe.experts.0.w3.weight\n",
      "layers.0.block_sparse_moe.experts.3.w1.weight layers.0.block_sparse_moe.experts.1.w1.weight\n",
      "layers.0.block_sparse_moe.experts.3.w2.weight layers.0.block_sparse_moe.experts.1.w2.weight\n",
      "layers.0.block_sparse_moe.experts.3.w3.weight layers.0.block_sparse_moe.experts.1.w3.weight\n",
      "layers.0.block_sparse_moe.experts.4.w1.weight layers.0.block_sparse_moe.experts.1.w1.weight\n",
      "layers.0.block_sparse_moe.experts.4.w2.weight layers.0.block_sparse_moe.experts.1.w2.weight\n",
      "layers.0.block_sparse_moe.experts.4.w3.weight layers.0.block_sparse_moe.experts.1.w3.weight\n",
      "layers.0.block_sparse_moe.experts.5.w1.weight layers.0.block_sparse_moe.experts.2.w1.weight\n",
      "layers.0.block_sparse_moe.experts.5.w2.weight layers.0.block_sparse_moe.experts.2.w2.weight\n",
      "layers.0.block_sparse_moe.experts.5.w3.weight layers.0.block_sparse_moe.experts.2.w3.weight\n",
      "layers.0.block_sparse_moe.experts.6.w1.weight layers.0.block_sparse_moe.experts.2.w1.weight\n",
      "layers.0.block_sparse_moe.experts.6.w2.weight layers.0.block_sparse_moe.experts.2.w2.weight\n",
      "layers.0.block_sparse_moe.experts.6.w3.weight layers.0.block_sparse_moe.experts.2.w3.weight\n",
      "layers.0.block_sparse_moe.experts.7.w1.weight layers.0.block_sparse_moe.experts.3.w1.weight\n",
      "layers.0.block_sparse_moe.experts.7.w2.weight layers.0.block_sparse_moe.experts.3.w2.weight\n",
      "layers.0.block_sparse_moe.experts.7.w3.weight layers.0.block_sparse_moe.experts.3.w3.weight\n",
      "layers.0.block_sparse_moe.experts.8.w1.weight layers.0.block_sparse_moe.experts.4.w1.weight\n",
      "layers.0.block_sparse_moe.experts.8.w2.weight layers.0.block_sparse_moe.experts.4.w2.weight\n",
      "layers.0.block_sparse_moe.experts.8.w3.weight layers.0.block_sparse_moe.experts.4.w3.weight\n",
      "layers.0.block_sparse_moe.experts.9.w1.weight layers.0.block_sparse_moe.experts.4.w1.weight\n",
      "layers.0.block_sparse_moe.experts.9.w2.weight layers.0.block_sparse_moe.experts.4.w2.weight\n",
      "layers.0.block_sparse_moe.experts.9.w3.weight layers.0.block_sparse_moe.experts.4.w3.weight\n",
      "layers.0.block_sparse_moe.experts.10.w1.weight layers.0.block_sparse_moe.experts.4.w1.weight\n",
      "layers.0.block_sparse_moe.experts.10.w2.weight layers.0.block_sparse_moe.experts.4.w2.weight\n",
      "layers.0.block_sparse_moe.experts.10.w3.weight layers.0.block_sparse_moe.experts.4.w3.weight\n",
      "layers.0.block_sparse_moe.experts.11.w1.weight layers.0.block_sparse_moe.experts.5.w1.weight\n",
      "layers.0.block_sparse_moe.experts.11.w2.weight layers.0.block_sparse_moe.experts.5.w2.weight\n",
      "layers.0.block_sparse_moe.experts.11.w3.weight layers.0.block_sparse_moe.experts.5.w3.weight\n",
      "layers.0.block_sparse_moe.experts.12.w1.weight layers.0.block_sparse_moe.experts.6.w1.weight\n",
      "layers.0.block_sparse_moe.experts.12.w2.weight layers.0.block_sparse_moe.experts.6.w2.weight\n",
      "layers.0.block_sparse_moe.experts.12.w3.weight layers.0.block_sparse_moe.experts.6.w3.weight\n",
      "layers.0.block_sparse_moe.experts.13.w1.weight layers.0.block_sparse_moe.experts.7.w1.weight\n",
      "layers.0.block_sparse_moe.experts.13.w2.weight layers.0.block_sparse_moe.experts.7.w2.weight\n",
      "layers.0.block_sparse_moe.experts.13.w3.weight layers.0.block_sparse_moe.experts.7.w3.weight\n",
      "layers.1.block_sparse_moe.experts.0.w1.weight layers.1.block_sparse_moe.experts.0.w1.weight\n",
      "layers.1.block_sparse_moe.experts.0.w2.weight layers.1.block_sparse_moe.experts.0.w2.weight\n",
      "layers.1.block_sparse_moe.experts.0.w3.weight layers.1.block_sparse_moe.experts.0.w3.weight\n",
      "layers.1.block_sparse_moe.experts.1.w1.weight layers.1.block_sparse_moe.experts.0.w1.weight\n",
      "layers.1.block_sparse_moe.experts.1.w2.weight layers.1.block_sparse_moe.experts.0.w2.weight\n",
      "layers.1.block_sparse_moe.experts.1.w3.weight layers.1.block_sparse_moe.experts.0.w3.weight\n",
      "layers.1.block_sparse_moe.experts.2.w1.weight layers.1.block_sparse_moe.experts.0.w1.weight\n",
      "layers.1.block_sparse_moe.experts.2.w2.weight layers.1.block_sparse_moe.experts.0.w2.weight\n",
      "layers.1.block_sparse_moe.experts.2.w3.weight layers.1.block_sparse_moe.experts.0.w3.weight\n",
      "layers.1.block_sparse_moe.experts.3.w1.weight layers.1.block_sparse_moe.experts.1.w1.weight\n",
      "layers.1.block_sparse_moe.experts.3.w2.weight layers.1.block_sparse_moe.experts.1.w2.weight\n",
      "layers.1.block_sparse_moe.experts.3.w3.weight layers.1.block_sparse_moe.experts.1.w3.weight\n",
      "layers.1.block_sparse_moe.experts.4.w1.weight layers.1.block_sparse_moe.experts.1.w1.weight\n",
      "layers.1.block_sparse_moe.experts.4.w2.weight layers.1.block_sparse_moe.experts.1.w2.weight\n",
      "layers.1.block_sparse_moe.experts.4.w3.weight layers.1.block_sparse_moe.experts.1.w3.weight\n",
      "layers.1.block_sparse_moe.experts.5.w1.weight layers.1.block_sparse_moe.experts.2.w1.weight\n",
      "layers.1.block_sparse_moe.experts.5.w2.weight layers.1.block_sparse_moe.experts.2.w2.weight\n",
      "layers.1.block_sparse_moe.experts.5.w3.weight layers.1.block_sparse_moe.experts.2.w3.weight\n",
      "layers.1.block_sparse_moe.experts.6.w1.weight layers.1.block_sparse_moe.experts.2.w1.weight\n",
      "layers.1.block_sparse_moe.experts.6.w2.weight layers.1.block_sparse_moe.experts.2.w2.weight\n",
      "layers.1.block_sparse_moe.experts.6.w3.weight layers.1.block_sparse_moe.experts.2.w3.weight\n",
      "layers.1.block_sparse_moe.experts.7.w1.weight layers.1.block_sparse_moe.experts.3.w1.weight\n",
      "layers.1.block_sparse_moe.experts.7.w2.weight layers.1.block_sparse_moe.experts.3.w2.weight\n",
      "layers.1.block_sparse_moe.experts.7.w3.weight layers.1.block_sparse_moe.experts.3.w3.weight\n",
      "layers.1.block_sparse_moe.experts.8.w1.weight layers.1.block_sparse_moe.experts.4.w1.weight\n",
      "layers.1.block_sparse_moe.experts.8.w2.weight layers.1.block_sparse_moe.experts.4.w2.weight\n",
      "layers.1.block_sparse_moe.experts.8.w3.weight layers.1.block_sparse_moe.experts.4.w3.weight\n",
      "layers.1.block_sparse_moe.experts.9.w1.weight layers.1.block_sparse_moe.experts.4.w1.weight\n",
      "layers.1.block_sparse_moe.experts.9.w2.weight layers.1.block_sparse_moe.experts.4.w2.weight\n",
      "layers.1.block_sparse_moe.experts.9.w3.weight layers.1.block_sparse_moe.experts.4.w3.weight\n",
      "layers.1.block_sparse_moe.experts.10.w1.weight layers.1.block_sparse_moe.experts.4.w1.weight\n",
      "layers.1.block_sparse_moe.experts.10.w2.weight layers.1.block_sparse_moe.experts.4.w2.weight\n",
      "layers.1.block_sparse_moe.experts.10.w3.weight layers.1.block_sparse_moe.experts.4.w3.weight\n",
      "layers.1.block_sparse_moe.experts.11.w1.weight layers.1.block_sparse_moe.experts.5.w1.weight\n",
      "layers.1.block_sparse_moe.experts.11.w2.weight layers.1.block_sparse_moe.experts.5.w2.weight\n",
      "layers.1.block_sparse_moe.experts.11.w3.weight layers.1.block_sparse_moe.experts.5.w3.weight\n",
      "layers.1.block_sparse_moe.experts.12.w1.weight layers.1.block_sparse_moe.experts.6.w1.weight\n",
      "layers.1.block_sparse_moe.experts.12.w2.weight layers.1.block_sparse_moe.experts.6.w2.weight\n",
      "layers.1.block_sparse_moe.experts.12.w3.weight layers.1.block_sparse_moe.experts.6.w3.weight\n",
      "layers.1.block_sparse_moe.experts.13.w1.weight layers.1.block_sparse_moe.experts.7.w1.weight\n",
      "layers.1.block_sparse_moe.experts.13.w2.weight layers.1.block_sparse_moe.experts.7.w2.weight\n",
      "layers.1.block_sparse_moe.experts.13.w3.weight layers.1.block_sparse_moe.experts.7.w3.weight\n",
      "layers.2.block_sparse_moe.experts.0.w1.weight layers.2.block_sparse_moe.experts.0.w1.weight\n",
      "layers.2.block_sparse_moe.experts.0.w2.weight layers.2.block_sparse_moe.experts.0.w2.weight\n",
      "layers.2.block_sparse_moe.experts.0.w3.weight layers.2.block_sparse_moe.experts.0.w3.weight\n",
      "layers.2.block_sparse_moe.experts.1.w1.weight layers.2.block_sparse_moe.experts.0.w1.weight\n",
      "layers.2.block_sparse_moe.experts.1.w2.weight layers.2.block_sparse_moe.experts.0.w2.weight\n",
      "layers.2.block_sparse_moe.experts.1.w3.weight layers.2.block_sparse_moe.experts.0.w3.weight\n",
      "layers.2.block_sparse_moe.experts.2.w1.weight layers.2.block_sparse_moe.experts.0.w1.weight\n",
      "layers.2.block_sparse_moe.experts.2.w2.weight layers.2.block_sparse_moe.experts.0.w2.weight\n",
      "layers.2.block_sparse_moe.experts.2.w3.weight layers.2.block_sparse_moe.experts.0.w3.weight\n",
      "layers.2.block_sparse_moe.experts.3.w1.weight layers.2.block_sparse_moe.experts.1.w1.weight\n",
      "layers.2.block_sparse_moe.experts.3.w2.weight layers.2.block_sparse_moe.experts.1.w2.weight\n",
      "layers.2.block_sparse_moe.experts.3.w3.weight layers.2.block_sparse_moe.experts.1.w3.weight\n",
      "layers.2.block_sparse_moe.experts.4.w1.weight layers.2.block_sparse_moe.experts.1.w1.weight\n",
      "layers.2.block_sparse_moe.experts.4.w2.weight layers.2.block_sparse_moe.experts.1.w2.weight\n",
      "layers.2.block_sparse_moe.experts.4.w3.weight layers.2.block_sparse_moe.experts.1.w3.weight\n",
      "layers.2.block_sparse_moe.experts.5.w1.weight layers.2.block_sparse_moe.experts.2.w1.weight\n",
      "layers.2.block_sparse_moe.experts.5.w2.weight layers.2.block_sparse_moe.experts.2.w2.weight\n",
      "layers.2.block_sparse_moe.experts.5.w3.weight layers.2.block_sparse_moe.experts.2.w3.weight\n",
      "layers.2.block_sparse_moe.experts.6.w1.weight layers.2.block_sparse_moe.experts.2.w1.weight\n",
      "layers.2.block_sparse_moe.experts.6.w2.weight layers.2.block_sparse_moe.experts.2.w2.weight\n",
      "layers.2.block_sparse_moe.experts.6.w3.weight layers.2.block_sparse_moe.experts.2.w3.weight\n",
      "layers.2.block_sparse_moe.experts.7.w1.weight layers.2.block_sparse_moe.experts.3.w1.weight\n",
      "layers.2.block_sparse_moe.experts.7.w2.weight layers.2.block_sparse_moe.experts.3.w2.weight\n",
      "layers.2.block_sparse_moe.experts.7.w3.weight layers.2.block_sparse_moe.experts.3.w3.weight\n",
      "layers.2.block_sparse_moe.experts.8.w1.weight layers.2.block_sparse_moe.experts.4.w1.weight\n",
      "layers.2.block_sparse_moe.experts.8.w2.weight layers.2.block_sparse_moe.experts.4.w2.weight\n",
      "layers.2.block_sparse_moe.experts.8.w3.weight layers.2.block_sparse_moe.experts.4.w3.weight\n",
      "layers.2.block_sparse_moe.experts.9.w1.weight layers.2.block_sparse_moe.experts.4.w1.weight\n",
      "layers.2.block_sparse_moe.experts.9.w2.weight layers.2.block_sparse_moe.experts.4.w2.weight\n",
      "layers.2.block_sparse_moe.experts.9.w3.weight layers.2.block_sparse_moe.experts.4.w3.weight\n",
      "layers.2.block_sparse_moe.experts.10.w1.weight layers.2.block_sparse_moe.experts.4.w1.weight\n",
      "layers.2.block_sparse_moe.experts.10.w2.weight layers.2.block_sparse_moe.experts.4.w2.weight\n",
      "layers.2.block_sparse_moe.experts.10.w3.weight layers.2.block_sparse_moe.experts.4.w3.weight\n",
      "layers.2.block_sparse_moe.experts.11.w1.weight layers.2.block_sparse_moe.experts.5.w1.weight\n",
      "layers.2.block_sparse_moe.experts.11.w2.weight layers.2.block_sparse_moe.experts.5.w2.weight\n",
      "layers.2.block_sparse_moe.experts.11.w3.weight layers.2.block_sparse_moe.experts.5.w3.weight\n",
      "layers.2.block_sparse_moe.experts.12.w1.weight layers.2.block_sparse_moe.experts.6.w1.weight\n",
      "layers.2.block_sparse_moe.experts.12.w2.weight layers.2.block_sparse_moe.experts.6.w2.weight\n",
      "layers.2.block_sparse_moe.experts.12.w3.weight layers.2.block_sparse_moe.experts.6.w3.weight\n",
      "layers.2.block_sparse_moe.experts.13.w1.weight layers.2.block_sparse_moe.experts.7.w1.weight\n",
      "layers.2.block_sparse_moe.experts.13.w2.weight layers.2.block_sparse_moe.experts.7.w2.weight\n",
      "layers.2.block_sparse_moe.experts.13.w3.weight layers.2.block_sparse_moe.experts.7.w3.weight\n",
      "layers.3.block_sparse_moe.experts.0.w1.weight layers.3.block_sparse_moe.experts.0.w1.weight\n",
      "layers.3.block_sparse_moe.experts.0.w2.weight layers.3.block_sparse_moe.experts.0.w2.weight\n",
      "layers.3.block_sparse_moe.experts.0.w3.weight layers.3.block_sparse_moe.experts.0.w3.weight\n",
      "layers.3.block_sparse_moe.experts.1.w1.weight layers.3.block_sparse_moe.experts.0.w1.weight\n",
      "layers.3.block_sparse_moe.experts.1.w2.weight layers.3.block_sparse_moe.experts.0.w2.weight\n",
      "layers.3.block_sparse_moe.experts.1.w3.weight layers.3.block_sparse_moe.experts.0.w3.weight\n",
      "layers.3.block_sparse_moe.experts.2.w1.weight layers.3.block_sparse_moe.experts.0.w1.weight\n",
      "layers.3.block_sparse_moe.experts.2.w2.weight layers.3.block_sparse_moe.experts.0.w2.weight\n",
      "layers.3.block_sparse_moe.experts.2.w3.weight layers.3.block_sparse_moe.experts.0.w3.weight\n",
      "layers.3.block_sparse_moe.experts.3.w1.weight layers.3.block_sparse_moe.experts.1.w1.weight\n",
      "layers.3.block_sparse_moe.experts.3.w2.weight layers.3.block_sparse_moe.experts.1.w2.weight\n",
      "layers.3.block_sparse_moe.experts.3.w3.weight layers.3.block_sparse_moe.experts.1.w3.weight\n",
      "layers.3.block_sparse_moe.experts.4.w1.weight layers.3.block_sparse_moe.experts.1.w1.weight\n",
      "layers.3.block_sparse_moe.experts.4.w2.weight layers.3.block_sparse_moe.experts.1.w2.weight\n",
      "layers.3.block_sparse_moe.experts.4.w3.weight layers.3.block_sparse_moe.experts.1.w3.weight\n",
      "layers.3.block_sparse_moe.experts.5.w1.weight layers.3.block_sparse_moe.experts.2.w1.weight\n",
      "layers.3.block_sparse_moe.experts.5.w2.weight layers.3.block_sparse_moe.experts.2.w2.weight\n",
      "layers.3.block_sparse_moe.experts.5.w3.weight layers.3.block_sparse_moe.experts.2.w3.weight\n",
      "layers.3.block_sparse_moe.experts.6.w1.weight layers.3.block_sparse_moe.experts.2.w1.weight\n",
      "layers.3.block_sparse_moe.experts.6.w2.weight layers.3.block_sparse_moe.experts.2.w2.weight\n",
      "layers.3.block_sparse_moe.experts.6.w3.weight layers.3.block_sparse_moe.experts.2.w3.weight\n",
      "layers.3.block_sparse_moe.experts.7.w1.weight layers.3.block_sparse_moe.experts.3.w1.weight\n",
      "layers.3.block_sparse_moe.experts.7.w2.weight layers.3.block_sparse_moe.experts.3.w2.weight\n",
      "layers.3.block_sparse_moe.experts.7.w3.weight layers.3.block_sparse_moe.experts.3.w3.weight\n",
      "layers.3.block_sparse_moe.experts.8.w1.weight layers.3.block_sparse_moe.experts.4.w1.weight\n",
      "layers.3.block_sparse_moe.experts.8.w2.weight layers.3.block_sparse_moe.experts.4.w2.weight\n",
      "layers.3.block_sparse_moe.experts.8.w3.weight layers.3.block_sparse_moe.experts.4.w3.weight\n",
      "layers.3.block_sparse_moe.experts.9.w1.weight layers.3.block_sparse_moe.experts.4.w1.weight\n",
      "layers.3.block_sparse_moe.experts.9.w2.weight layers.3.block_sparse_moe.experts.4.w2.weight\n",
      "layers.3.block_sparse_moe.experts.9.w3.weight layers.3.block_sparse_moe.experts.4.w3.weight\n",
      "layers.3.block_sparse_moe.experts.10.w1.weight layers.3.block_sparse_moe.experts.4.w1.weight\n",
      "layers.3.block_sparse_moe.experts.10.w2.weight layers.3.block_sparse_moe.experts.4.w2.weight\n",
      "layers.3.block_sparse_moe.experts.10.w3.weight layers.3.block_sparse_moe.experts.4.w3.weight\n",
      "layers.3.block_sparse_moe.experts.11.w1.weight layers.3.block_sparse_moe.experts.5.w1.weight\n",
      "layers.3.block_sparse_moe.experts.11.w2.weight layers.3.block_sparse_moe.experts.5.w2.weight\n",
      "layers.3.block_sparse_moe.experts.11.w3.weight layers.3.block_sparse_moe.experts.5.w3.weight\n",
      "layers.3.block_sparse_moe.experts.12.w1.weight layers.3.block_sparse_moe.experts.6.w1.weight\n",
      "layers.3.block_sparse_moe.experts.12.w2.weight layers.3.block_sparse_moe.experts.6.w2.weight\n",
      "layers.3.block_sparse_moe.experts.12.w3.weight layers.3.block_sparse_moe.experts.6.w3.weight\n",
      "layers.3.block_sparse_moe.experts.13.w1.weight layers.3.block_sparse_moe.experts.7.w1.weight\n",
      "layers.3.block_sparse_moe.experts.13.w2.weight layers.3.block_sparse_moe.experts.7.w2.weight\n",
      "layers.3.block_sparse_moe.experts.13.w3.weight layers.3.block_sparse_moe.experts.7.w3.weight\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get states of the initial model\n",
    "initial_state_dict = initial_model.state_dict() # this Dict[str, torch.Tensor]\n",
    "\n",
    "\n",
    "\n",
    "# A lot of machinery for the very simple task of remapping the experts\n",
    "\n",
    "def get_parts(k):\n",
    "    parts = k.split('.')\n",
    "    idx = parts.index('block_sparse_moe')\n",
    "\n",
    "    layer_idx = int(parts[idx - 1])\n",
    "    expert_idx = int(parts[idx + 2])\n",
    "    prefix = '.'.join(parts[:idx - 1])\n",
    "    suffix = '.'.join(parts[idx + 3:])\n",
    "\n",
    "    return layer_idx, expert_idx, prefix, suffix\n",
    "\n",
    "\n",
    "def get_experts_paths(initial_state_dict):\n",
    "    '''\n",
    "    Return the path to the top level of an expert block. In practice it has different children w1, w2, w3\n",
    "    We remove the children to get the path to the top level\n",
    "    '''\n",
    "    expert_weights_names = [k for k in initial_state_dict.keys() if 'block_sparse_moe.experts' in k]\n",
    "    experts_paths = set()\n",
    "    for k in sorted(expert_weights_names):\n",
    "        layer_idx, expert_idx, prefix, suffix = get_parts(k)\n",
    "\n",
    "        expert_path = f\"{prefix}.{layer_idx}.block_sparse_moe.experts.{expert_idx}\"\n",
    "        experts_paths.add(expert_path)\n",
    "\n",
    "    return experts_paths\n",
    "\n",
    "\n",
    "def get_all_paths_for_experts(initial_state_dict):\n",
    "    '''\n",
    "    :return: Dict[str, List[str]] where the key is the path to the top level of the expert block and the value is a list of the children paths\n",
    "    '''\n",
    "    experts_paths = get_experts_paths(initial_state_dict)\n",
    "\n",
    "    all_paths = {}\n",
    "\n",
    "    for expert_path in experts_paths:\n",
    "        all_paths[expert_path] = [k[len(expert_path) + 1:]\n",
    "                                  for k in initial_state_dict.keys() if expert_path in k]\n",
    "\n",
    "    return all_paths\n",
    "\n",
    "\n",
    "def create_duplicated_names(all_paths, experts_duplication):\n",
    "    '''\n",
    "    Build the new names for the duplicated experts and their children\n",
    "    \n",
    "    expert_id | new_id\n",
    "    0         | 0\n",
    "    0         | 1\n",
    "    0         | 2\n",
    "    1         | 3\n",
    "    1         | 4\n",
    "    2         | 5\n",
    "    2         | 6\n",
    "    ...\n",
    "    \n",
    "    Expert 0 is duplicated 3 times, expert 1 is duplicated 2 times, expert 2 is duplicated 2 times, etc.\n",
    "    \n",
    "    :return: Dict[str, str] where the key is the new name and the value is the old name\n",
    "    '''\n",
    "    layer_experts_current = {}\n",
    "\n",
    "    expert_weights_path: Dict[str, str] = {}\n",
    "\n",
    "    for expert_path, paths in sorted(all_paths.items()):\n",
    "        layer_idx, expert_idx, prefix, _ = get_parts(expert_path)\n",
    "\n",
    "        if layer_idx not in layer_experts_current:\n",
    "            layer_experts_current[layer_idx] = 0\n",
    "\n",
    "        layer_expert_idx = layer_experts_current[layer_idx]\n",
    "        for _ in range(experts_duplication[layer_idx][expert_idx]):\n",
    "            current_expert_path = f\"{prefix}.{layer_idx}.block_sparse_moe.experts.{layer_expert_idx}\"\n",
    "            layer_expert_idx += 1\n",
    "            for p in paths:\n",
    "                expert_weights_path[f\"{current_expert_path}.{p}\"] = f\"{expert_path}.{p}\"\n",
    "\n",
    "        layer_experts_current[layer_idx] = layer_expert_idx\n",
    "            \n",
    "    return expert_weights_path\n",
    "\n",
    "\n",
    "def convert_initial_state_dict_to_dupxtral(initial_state_dict, config_dupxtral):\n",
    "    '''\n",
    "    Convert the initial state_dict to the dupxtral model state_dict\n",
    "    :param initial_state_dict: \n",
    "    :param config_dupxtral: \n",
    "    :return: Dupxtral model state_dict Dict[str, torch.Tensor]\n",
    "    '''\n",
    "    expert_weights_names = [k for k in initial_state_dict.keys() if 'block_sparse_moe.experts' in k]\n",
    "\n",
    "    new_state_dict = {}\n",
    "\n",
    "    # copy everything from the initial state_dict but the expert weights\n",
    "    for k, v in initial_state_dict.items():\n",
    "        if k not in expert_weights_names:\n",
    "            new_state_dict[k] = v\n",
    "\n",
    "    all_paths = get_all_paths_for_experts(initial_state_dict)\n",
    "    \n",
    "    expert_weights_path = create_duplicated_names(all_paths, config_dupxtral.experts_duplicate)\n",
    "    \n",
    "    # actually duplicate the weights based on new and old names\n",
    "    for new_name, old_name in expert_weights_path.items():\n",
    "        new_state_dict[new_name] = initial_state_dict[old_name]\n",
    "        print(new_name, old_name)\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "new_state_dict = convert_initial_state_dict_to_dupxtral(initial_state_dict, config_dupxtral)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe509ff7f1439455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.316930Z",
     "start_time": "2024-06-22T15:41:41.302845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupxtral_model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6515b5705e47cae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.323176Z",
     "start_time": "2024-06-22T15:41:41.319659Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# fake tokenized input for testing\n",
    "input_ids = torch.randint(0, 128, (3, 11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110e49914deb893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.569704Z",
     "start_time": "2024-06-22T15:41:41.324628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0842,  1.0685,  0.3184, -0.9867,  0.4161,  0.4228, -0.3108, -0.9868,\n",
       "         2.4460], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output with dupxtral model\n",
    "\n",
    "output = dupxtral_model(input_ids)\n",
    "output.last_hidden_state[0, 0, :9]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "404014c5eae75d02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.584552Z",
     "start_time": "2024-06-22T15:41:41.570786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0842,  1.0685,  0.3184, -0.9867,  0.4161,  0.4228, -0.3108, -0.9868,\n",
       "         2.4460], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output with initial model\n",
    "\n",
    "output_initial = initial_model(input_ids)\n",
    "output_initial.last_hidden_state[0, 0, :9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e10b0a2d992ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:41.588247Z",
     "start_time": "2024-06-22T15:41:41.585491Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
